{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH1rqrtgPnVx",
        "outputId": "75906716-c4fb-4426-e317-745367424ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow\n",
        "!pip install -q streamlit\n",
        "!pip install -q Pillow\n",
        "!pip install -q numpy\n",
        "!pip install -q matplotlib\n",
        "!pip install -q pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuzO0MPqwbMC",
        "outputId": "999e11e0-aaa0-498a-a2a9-1f3d003fbc7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btRIhs1pwbPp",
        "outputId": "c7f88fbf-1c2d-4327-e926-04a8a7ffde35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile train.py\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "DATASET_PATH = '/content/drive/My Drive/Colab Notebooks/data'\n",
        "TRAIN_DIR = os.path.join(DATASET_PATH, 'train')\n",
        "VALIDATION_DIR = os.path.join(DATASET_PATH, 'val')\n",
        "\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 15\n",
        "\n",
        "if not os.path.exists(TRAIN_DIR) or not os.path.exists(VALIDATION_DIR):\n",
        "    raise FileNotFoundError(f\"Missing required directories. Please ensure '{TRAIN_DIR}' and '{VALIDATION_DIR}' exist.\")\n",
        "\n",
        "NUM_CLASSES = len(os.listdir(TRAIN_DIR))\n",
        "print(f\"Number of classes detected: {NUM_CLASSES}\")\n",
        "\n",
        "# --- 2. DATA PREPROCESSING AND AUGMENTATION ---\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    VALIDATION_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(\"Class names:\", class_names)\n",
        "\n",
        "# --- 3. MODEL TRAINING ---\n",
        "def create_custom_cnn_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_transfer_learning_model():\n",
        "    base_model = EfficientNetB0(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
        "                                include_top=False,\n",
        "                                weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "print(\"\\n--- Training Custom CNN Model ---\")\n",
        "cnn_model = create_custom_cnn_model()\n",
        "cnn_history = cnn_model.fit(\n",
        "    train_generator,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training Transfer Learning (EfficientNetB0) Model ---\")\n",
        "tl_model = create_transfer_learning_model()\n",
        "tl_history = tl_model.fit(\n",
        "    train_generator,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "cnn_loss, cnn_acc = cnn_model.evaluate(validation_generator)\n",
        "tl_loss, tl_acc = tl_model.evaluate(validation_generator)\n",
        "\n",
        "print(f\"\\nCustom CNN Validation Accuracy: {cnn_acc:.4f}\")\n",
        "print(f\"Transfer Learning (EfficientNetB0) Validation Accuracy: {tl_acc:.4f}\")\n",
        "\n",
        "if tl_acc > cnn_acc:\n",
        "    print(\"Saving the Transfer Learning model as 'best_model.h5'\")\n",
        "    tl_model.save('best_model.h5')\n",
        "    best_model_history = tl_history\n",
        "else:\n",
        "    print(\"Saving the Custom CNN model as 'best_model.h5'\")\n",
        "    cnn_model.save('best_model.h5')\n",
        "    best_model_history = cnn_history\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(best_model_history.history['accuracy'])\n",
        "plt.plot(best_model_history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.savefig('accuracy_plot.png')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(best_model_history.history['loss'])\n",
        "plt.plot(best_model_history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.savefig('loss_plot.png')\n",
        "\n",
        "print(\"Training completed. Plots saved as 'accuracy_plot.png' and 'loss_plot.png'\")\n",
        "print(\"Best model saved as 'best_model.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DqU2_wDwbgQ",
        "outputId": "f5569a4a-c25a-4c8b-b734-afae80a944b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-13 05:16:40.642724: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755062200.674715    1142 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755062200.684738    1142 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755062200.708726    1142 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755062200.708764    1142 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755062200.708772    1142 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755062200.708778    1142 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-13 05:16:40.715317: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Number of classes detected: 11\n",
            "Found 6225 images belonging to 11 classes.\n",
            "Found 916 images belonging to 11 classes.\n",
            "Class names: ['animal fish', 'animal fish bass', 'fish sea_food black_sea_sprat', 'fish sea_food gilt_head_bream', 'fish sea_food hourse_mackerel', 'fish sea_food red_mullet', 'fish sea_food red_sea_bream', 'fish sea_food sea_bass', 'fish sea_food shrimp', 'fish sea_food striped_red_mullet', 'fish sea_food trout']\n",
            "\n",
            "--- Training Custom CNN Model ---\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2025-08-13 05:16:55.646068: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1755062215.647505    1142 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "Epoch 1/15\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1755062269.479145    1240 service.cc:152] XLA service 0x79e1d8006310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1755062269.479207    1240 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-08-13 05:17:49.550449: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1755062269.874253    1240 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "2025-08-13 05:17:50.882222: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.9 = (f32[32,32,222,222]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,224,224]{3,2,1,0} %bitcast.4702, f32[32,3,3,3]{3,2,1,0} %bitcast.4709, f32[32]{0} %bitcast.5247), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-08-13 05:17:51.022089: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.10 = (f32[32,64,109,109]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,111,111]{3,2,1,0} %bitcast.5315, f32[64,32,3,3]{3,2,1,0} %bitcast.4730, f32[64]{0} %bitcast.5375), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-08-13 05:17:51.334146: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[32,128,52,52]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,54,54]{3,2,1,0} %bitcast.5439, f32[128,64,3,3]{3,2,1,0} %bitcast.4749, f32[128]{0} %bitcast.5499), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1755062275.712636    1240 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m  6/195\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m43:30\u001b[0m 14s/step - accuracy: 0.0426 - loss: 4.96372025-08-13 05:19:14.077663: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.9 = (f32[17,32,222,222]{3,2,1,0}, u8[0]{0}) custom-call(f32[17,3,224,224]{3,2,1,0} %bitcast.4702, f32[32,3,3,3]{3,2,1,0} %bitcast.4709, f32[32]{0} %bitcast.5247), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-08-13 05:19:14.225349: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.10 = (f32[17,64,109,109]{3,2,1,0}, u8[0]{0}) custom-call(f32[17,32,111,111]{3,2,1,0} %bitcast.5315, f32[64,32,3,3]{3,2,1,0} %bitcast.4730, f32[64]{0} %bitcast.5375), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2025-08-13 05:19:14.381558: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[17,128,52,52]{3,2,1,0}, u8[0]{0}) custom-call(f32[17,64,54,54]{3,2,1,0} %bitcast.5439, f32[128,64,3,3]{3,2,1,0} %bitcast.4749, f32[128]{0} %bitcast.5499), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m 59/195\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m33:11\u001b[0m 15s/step - accuracy: 0.1621 - loss: 2.9869^C\n"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv7hECkswbkM",
        "outputId": "1f6dfdc0-b307-400f-901f-84f77220d4c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "try:\n",
        "    model = tf.keras.models.load_model('best_model.h5')\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading model: {e}\")\n",
        "    st.info(\"Please run `train.py` first to create the model file.\")\n",
        "    st.stop()\n",
        "\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "DATASET_PATH = '/content/drive/My Drive/Colab Notebooks/data'\n",
        "TRAIN_DIR = os.path.join(DATASET_PATH, 'train')\n",
        "if os.path.exists(TRAIN_DIR):\n",
        "    class_names = sorted([d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))])\n",
        "else:\n",
        "    class_names = [\"Class 1\", \"Class 2\", \"Class 3\"]\n",
        "    st.warning(\"Could not find the 'data/train' directory. Using placeholder class names.\")\n",
        "\n",
        "st.set_page_config(page_title=\"Fish Species Classifier\", layout=\"centered\")\n",
        "st.title(\"üêü Multiclass Fish Image Classification\")\n",
        "st.markdown(\"Upload an image of a fish and the model will predict its species.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a fish image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "\n",
        "    if st.button(\"Predict\"):\n",
        "        with st.spinner(\"Classifying...\"):\n",
        "            img_resized = image.resize(IMAGE_SIZE)\n",
        "            img_array = np.array(img_resized)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            img_array = img_array / 255.0\n",
        "\n",
        "            predictions = model.predict(img_array)\n",
        "            predicted_class_index = np.argmax(predictions)\n",
        "            predicted_class_name = class_names[predicted_class_index]\n",
        "            confidence_score = predictions[0][predicted_class_index]\n",
        "\n",
        "            st.success(f\"Prediction: **{predicted_class_name}**\")\n",
        "            st.info(f\"Confidence: {confidence_score*100:.2f}%\")\n",
        "\n",
        "            st.subheader(\"All Class Probabilities\")\n",
        "            for i, (name, score) in enumerate(zip(class_names, predictions[0])):\n",
        "                st.write(f\"- **{name}**: {score*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmKfwfNx8Ypt",
        "outputId": "5141fa6e-b2a3-4c10-ecca-dc9156ea9c52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Streamlit app...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-08-11T16:58:47+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-08-11T16:58:47+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-08-11T16:58:47+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "CRITICAL:pyngrok.process.ngrok:t=2025-08-11T16:58:47+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error starting ngrok tunnel: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n.\n",
            "Please make sure you have an ngrok authtoken configured.\n",
            "Go to https://dashboard.ngrok.com/auth/your-authtoken to get one.\n",
            "Then run: !ngrok config add-authtoken YOUR_AUTHTOKEN_HERE\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', 'app.py', '--server.port...>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Starting Streamlit app...\")\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Get ngrok's authentication token from the settings\n",
        "# You may need to get one from https://dashboard.ngrok.com/auth/your-authtoken\n",
        "# If the command below fails, you can run: !ngrok config add-authtoken YOUR_AUTHTOKEN_HERE\n",
        "try:\n",
        "    ngrok.kill()\n",
        "    ngrok_tunnel = ngrok.connect(addr=8501, bind_tls=True)\n",
        "    print(f\"Your Streamlit app is running at: {ngrok_tunnel.public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok tunnel: {e}\")\n",
        "    print(\"Please make sure you have an ngrok authtoken configured.\")\n",
        "    print(\"Go to https://dashboard.ngrok.com/auth/your-authtoken to get one.\")\n",
        "    print(\"Then run: !ngrok config add-authtoken YOUR_AUTHTOKEN_HERE\")\n",
        "\n",
        "\n",
        "# Start the Streamlit app in the background\n",
        "subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVMIFcut8Ymu",
        "outputId": "28a81ef8-28fc-4712-ca47-133898bd6c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Streamlit app...\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Your Streamlit app is running at: https://0d876223e6e9.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Step 6: Run the Streamlit App\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"Starting Streamlit app...\")\n",
        "\n",
        "# 1. Configure ngrok with your personal authtoken\n",
        "# This command needs to be run only once.\n",
        "# This configures ngrok to use your verified account.\n",
        "!ngrok config add-authtoken 3192922EzP7gHi8re9CwKPGKOiv_6FfdFhfDY3SRc4ndhqBbp\n",
        "\n",
        "# 2. Start the Streamlit app and create a public URL\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    # Kill any existing ngrok tunnels to prevent conflicts\n",
        "    ngrok.kill()\n",
        "\n",
        "    # Create a tunnel for the Streamlit app, which runs on port 8501\n",
        "    ngrok_tunnel = ngrok.connect(addr=8501, bind_tls=True)\n",
        "\n",
        "    print(f\"Your Streamlit app is running at: {ngrok_tunnel.public_url}\")\n",
        "\n",
        "    # Start the Streamlit app in the background\n",
        "    subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok tunnel: {e}\")\n",
        "    print(\"Please check that your authtoken is correct and try again.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TsqfNBlDOtU",
        "outputId": "12ef53cf-1639-48bd-9465-6ce36428176b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ],
      "source": [
        "!pkill streamlit\n",
        "!nohup streamlit run app.py &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5VHE3TZ8YkR",
        "outputId": "1cb63452-6f2f-4889-9579-2ef0202479ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Streamlit app...\n",
            "Your Streamlit app is running at: https://03d321b6442c.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Final step to run your Streamlit app\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"Starting Streamlit app...\")\n",
        "\n",
        "# This command kills any existing ngrok sessions.\n",
        "# This prevents the '1 simultaneous ngrok agent sessions' error.\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "\n",
        "# Now, we start the ngrok tunnel.\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "try:\n",
        "    # Create a tunnel for the Streamlit app, which runs on port 8501\n",
        "    ngrok_tunnel = ngrok.connect(addr=8501, bind_tls=True)\n",
        "\n",
        "    print(f\"Your Streamlit app is running at: {ngrok_tunnel.public_url}\")\n",
        "\n",
        "    # Start the Streamlit app in the background\n",
        "    subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok tunnel: {e}\")\n",
        "    print(\"Please check that your authtoken is correct and try again.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNyOvc-iE4uD"
      },
      "outputs": [],
      "source": [
        "These one please execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWAZ3QpjE4ql",
        "outputId": "b27ab0ea-9a40-4112-855f-76c6b88344f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Installing necessary libraries...\n",
            "Libraries installed successfully.\n",
            "\n",
            "Step 2: Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted.\n",
            "\n",
            "Step 3: Creating `train.py` script...\n",
            "`train.py` script created.\n",
            "\n",
            "Step 4: Starting model training...\n",
            "2025-08-12 08:17:50.353008: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754986670.379711    1806 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754986670.387793    1806 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754986670.407465    1806 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754986670.407514    1806 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754986670.407519    1806 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754986670.407522    1806 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-12 08:17:50.413342: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Number of classes detected: 11\n",
            "Found 1045 images belonging to 11 classes.\n",
            "Found 916 images belonging to 11 classes.\n",
            "Class names: ['animal fish', 'animal fish bass', 'fish sea_food black_sea_sprat', 'fish sea_food gilt_head_bream', 'fish sea_food hourse_mackerel', 'fish sea_food red_mullet', 'fish sea_food red_sea_bream', 'fish sea_food sea_bass', 'fish sea_food shrimp', 'fish sea_food striped_red_mullet', 'fish sea_food trout']\n",
            "\n",
            "--- Training Transfer Learning (EfficientNetB0) Model with Fine-Tuning ---\n",
            "2025-08-12 08:18:02.560476: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "Epoch 1/30\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.4244 - loss: 3.4637\n",
            "Epoch 1: val_accuracy improved from -inf to 0.10917, saving model to best_model.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m831s\u001b[0m 25s/step - accuracy: 0.4255 - loss: 3.4448 - val_accuracy: 0.1092 - val_loss: 34.8608\n",
            "Epoch 2/30\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.4985 - loss: 1.2694\n",
            "Epoch 2: val_accuracy did not improve from 0.10917\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 13s/step - accuracy: 0.4986 - loss: 1.2642 - val_accuracy: 0.1092 - val_loss: 17.1782\n",
            "Epoch 3/30\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.4817 - loss: 0.8388\n",
            "Epoch 3: val_accuracy did not improve from 0.10917\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 12s/step - accuracy: 0.4827 - loss: 0.8371 - val_accuracy: 0.1070 - val_loss: 9.9124\n",
            "Epoch 4/30\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.4609 - loss: 0.7385\n",
            "Epoch 4: val_accuracy did not improve from 0.10917\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 13s/step - accuracy: 0.4613 - loss: 0.7382 - val_accuracy: 0.1070 - val_loss: 11.3684\n",
            "Epoch 5/30\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.4933 - loss: 0.7302\n",
            "Epoch 5: val_accuracy did not improve from 0.10917\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 11s/step - accuracy: 0.4937 - loss: 0.7299 - val_accuracy: 0.1070 - val_loss: 12.1580\n",
            "Epoch 6/30\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.5056 - loss: 0.7182\n",
            "Epoch 6: val_accuracy did not improve from 0.10917\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 14s/step - accuracy: 0.5051 - loss: 0.7184 - val_accuracy: 0.1070 - val_loss: 12.4009\n",
            "Epoch 7/30\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.5318 - loss: 0.7189\n",
            "Epoch 7: val_accuracy did not improve from 0.10917\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 12s/step - accuracy: 0.5310 - loss: 0.7190 - val_accuracy: 0.1070 - val_loss: 13.0065\n",
            "Epoch 8/30\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - accuracy: 0.5311 - loss: 0.7232\n",
            "Epoch 8: val_accuracy did not improve from 0.10917\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 11s/step - accuracy: 0.5314 - loss: 0.7229 - val_accuracy: 0.1070 - val_loss: 14.1704\n",
            "Training completed. Plots saved as 'accuracy_plot.png' and 'loss_plot.png'\n",
            "Best model saved as 'best_model.h5'\n",
            "\n",
            "Step 5: Creating `app.py` script...\n",
            "`app.py` script created.\n",
            "\n",
            "Step 6: Starting Streamlit app...\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Your Streamlit app is running at: https://0452fa5c5c68.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Corrected and Consolidated Google Colab Code\n",
        "# All steps are now in a single block to prevent execution errors.\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# --- Step 1: Install Libraries ---\n",
        "print(\"Step 1: Installing necessary libraries...\")\n",
        "# We use a non-interactive installation with -q to avoid any prompts\n",
        "# The libraries are installed at the beginning of the notebook's lifecycle\n",
        "!pip install -q tensorflow streamlit Pillow numpy matplotlib pyngrok\n",
        "print(\"Libraries installed successfully.\")\n",
        "\n",
        "# --- Step 2: Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "print(\"\\nStep 2: Mounting Google Drive...\")\n",
        "# This will prompt you to authorize Colab to access your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted.\")\n",
        "\n",
        "# --- Step 3: Write the train.py script (Improved Version) ---\n",
        "# This is a cell magic, it must be at the top of the cell it writes to.\n",
        "# We are writing the entire Python script into a file named train.py\n",
        "# This script contains the improved training logic with callbacks.\n",
        "# A new cell magic `%%writefile train.py` starts a new file write\n",
        "# and all subsequent lines in this cell are written to `train.py`.\n",
        "# We have to execute these as separate cells for them to work, but\n",
        "# we are creating the script files in this code and then running them\n",
        "# with a subprocess command.\n",
        "\n",
        "# The use of `%%writefile` in a separate block for each file is the\n",
        "# correct way to handle this. Since the user's previous code was\n",
        "# a single cell, the issue was likely with how it was executed.\n",
        "# This code structure should work correctly.\n",
        "\n",
        "# --- Step 3: Write the train.py script (Improved Version) ---\n",
        "# The code for writing the file is encapsulated within a Python script\n",
        "# that is executed, rather than using the cell magic directly.\n",
        "# This is a robust way to ensure it works within the single block.\n",
        "\n",
        "print(\"\\nStep 3: Creating `train.py` script...\")\n",
        "with open('train.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "# IMPORTANT: Update this path to where your 'data' folder is on Google Drive\n",
        "DATASET_PATH = '/content/drive/My Drive/Colab Notebooks/data'\n",
        "TRAIN_DIR = os.path.join(DATASET_PATH, 'train')\n",
        "VALIDATION_DIR = os.path.join(DATASET_PATH, 'val')\n",
        "\n",
        "IMAGE_SIZE = (300, 300)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 30\n",
        "\n",
        "if not os.path.exists(TRAIN_DIR) or not os.path.exists(VALIDATION_DIR):\n",
        "    raise FileNotFoundError(f\"Missing required directories. Please ensure '{TRAIN_DIR}' and '{VALIDATION_DIR}' exist.\")\n",
        "\n",
        "NUM_CLASSES = len(os.listdir(TRAIN_DIR))\n",
        "print(f\"Number of classes detected: {NUM_CLASSES}\")\n",
        "\n",
        "# --- 2. DATA PREPROCESSING AND AUGMENTATION ---\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    VALIDATION_DIR,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "class_names = sorted(list(train_generator.class_indices.keys()))\n",
        "print(\"Class names:\", class_names)\n",
        "\n",
        "# --- 3. MODEL TRAINING WITH FINE-TUNING ---\n",
        "print(\"\\\\n--- Training Transfer Learning (EfficientNetB0) Model with Fine-Tuning ---\")\n",
        "\n",
        "base_model = EfficientNetB0(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
        "                            include_top=False,\n",
        "                            weights='imagenet')\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='best_model.h5',\n",
        "    save_best_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[checkpoint_callback, early_stopping_callback]\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.savefig('accuracy_plot.png')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.savefig('loss_plot.png')\n",
        "\n",
        "print(\"Training completed. Plots saved as 'accuracy_plot.png' and 'loss_plot.png'\")\n",
        "print(\"Best model saved as 'best_model.h5'\")\n",
        "\"\"\")\n",
        "print(\"`train.py` script created.\")\n",
        "\n",
        "\n",
        "# --- Step 4: Run the training script ---\n",
        "print(\"\\nStep 4: Starting model training...\")\n",
        "# The !python command runs the external script we just wrote\n",
        "!python train.py\n",
        "\n",
        "# --- Step 5: Write the app.py script ---\n",
        "print(\"\\nStep 5: Creating `app.py` script...\")\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "try:\n",
        "    model = tf.keras.models.load_model('best_model.h5')\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading model: {e}\")\n",
        "    st.info(\"Please run `train.py` first to create the model file.\")\n",
        "    st.stop()\n",
        "\n",
        "IMAGE_SIZE = (300, 300)\n",
        "\n",
        "DATASET_PATH = '/content/drive/My Drive/Colab Notebooks/data'\n",
        "TRAIN_DIR = os.path.join(DATASET_PATH, 'train')\n",
        "if os.path.exists(TRAIN_DIR):\n",
        "    class_names = sorted([d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))])\n",
        "else:\n",
        "    class_names = [\"Class 1\", \"Class 2\", \"Class 3\"]\n",
        "    st.warning(\"Could not find the 'data/train' directory. Using placeholder class names.\")\n",
        "\n",
        "st.set_page_config(page_title=\"Fish Species Classifier\", layout=\"centered\")\n",
        "st.title(\"üêü Multiclass Fish Image Classification\")\n",
        "st.markdown(\"Upload an image of a fish and the model will predict its species.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a fish image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "\n",
        "    if st.button(\"Predict\"):\n",
        "        with st.spinner(\"Classifying...\"):\n",
        "            img_resized = image.resize(IMAGE_SIZE)\n",
        "            img_array = np.array(img_resized)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "            img_array = img_array / 255.0\n",
        "\n",
        "            predictions = model.predict(img_array)\n",
        "            predicted_class_index = np.argmax(predictions)\n",
        "            predicted_class_name = class_names[predicted_class_index]\n",
        "            confidence_score = predictions[0][predicted_class_index]\n",
        "\n",
        "            st.success(f\"Prediction: **{predicted_class_name}**\")\n",
        "            st.info(f\"Confidence: {confidence_score*100:.2f}%\")\n",
        "\n",
        "            st.subheader(\"All Class Probabilities\")\n",
        "            for i, (name, score) in enumerate(zip(class_names, predictions[0])):\n",
        "                st.write(f\"- **{name}**: {score*100:.2f}%\")\n",
        "\"\"\")\n",
        "print(\"`app.py` script created.\")\n",
        "\n",
        "# --- Step 6: Run Streamlit and expose it to a public URL with ngrok ---\n",
        "print(\"\\nStep 6: Starting Streamlit app...\")\n",
        "\n",
        "try:\n",
        "    ngrok.kill()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# IMPORTANT: You must replace the authtoken below with your own.\n",
        "# You can get one for free at https://ngrok.com/\n",
        "!ngrok config add-authtoken 3192922EzP7gHi8re9CwKPGKOiv_6FfdFhfDY3SRc4ndhqBbp\n",
        "\n",
        "try:\n",
        "    ngrok_tunnel = ngrok.connect(addr=8501, bind_tls=True)\n",
        "    print(f\"Your Streamlit app is running at: {ngrok_tunnel.public_url}\")\n",
        "\n",
        "    subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok tunnel: {e}\")\n",
        "    print(\"Please check that your authtoken is correct and try again.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmqisS-5E4oN",
        "outputId": "86ebb02c-da36-442c-8d55-bef5c0d7dd4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step 6: Starting Streamlit app...\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Your Streamlit app is running at: https://9288ef0a20fc.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Step 6: Run Streamlit and expose it to a public URL with ngrok ---\n",
        "print(\"\\nStep 6: Starting Streamlit app...\")\n",
        "\n",
        "try:\n",
        "    ngrok.kill()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# IMPORTANT: You must replace the authtoken below with your own.\n",
        "# You can get one for free at https://ngrok.com/\n",
        "!ngrok config add-authtoken 3192922EzP7gHi8re9CwKPGKOiv_6FfdFhfDY3SRc4ndhqBbp\n",
        "\n",
        "try:\n",
        "    ngrok_tunnel = ngrok.connect(addr=8501, bind_tls=True)\n",
        "    print(f\"Your Streamlit app is running at: {ngrok_tunnel.public_url}\")\n",
        "\n",
        "    subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok tunnel: {e}\")\n",
        "    print(\"Please check that your authtoken is correct and try again.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQvgzkZyHPkW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwKR-WLJ5QKv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZipQPtt5Rf1",
        "outputId": "49b14d1e-6bf2-4619-8c9f-46ed89cd5b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Installing necessary libraries...\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# Corrected Fish Classification Project with Hugging Face Vision Transformer\n",
        "# This code fixes the TypeError and adds a robust ngrok session handler.\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# --- Step 1: Install Libraries ---\n",
        "print(\"Step 1: Installing necessary libraries...\")\n",
        "# Install Hugging Face transformers, datasets, and evaluate\n",
        "!pip install -q transformers datasets Pillow numpy matplotlib streamlit pyngrok evaluate\n",
        "print(\"Libraries installed successfully.\")\n",
        "\n",
        "# --- Step 2: Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "print(\"\\nStep 2: Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted.\")\n",
        "\n",
        "# --- Step 3: Write the train.py script with Hugging Face logic ---\n",
        "print(\"\\nStep 3: Creating `train.py` script with Hugging Face Vision Transformer...\")\n",
        "with open('train.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# --- 1. CONFIGURATION ---\n",
        "# Please ensure this path is correct for your dataset\n",
        "DATASET_PATH = '/content/drive/My Drive/Colab Notebooks/data'\n",
        "TRAIN_DIR = os.path.join(DATASET_PATH, 'train')\n",
        "VAL_DIR = os.path.join(DATASET_PATH, 'val')\n",
        "\n",
        "if not os.path.exists(TRAIN_DIR) or not os.path.exists(VAL_DIR):\n",
        "    raise FileNotFoundError(f\"Dataset path '{DATASET_PATH}' not found. Please check your Google Drive.\")\n",
        "\n",
        "MODEL_CHECKPOINT = \"google/vit-base-patch16-224-in21k\" # A powerful pre-trained Vision Transformer\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "# --- 2. DATA PREPARATION FOR HUGGING FACE DATASETS ---\n",
        "print(\"Preparing dataset...\")\n",
        "\n",
        "# Get ALL unique labels from both train and val directories\n",
        "all_labels = set(os.listdir(TRAIN_DIR)) | set(os.listdir(VAL_DIR))\n",
        "labels = sorted(list(all_labels))\n",
        "label2id = {label: i for i, label in enumerate(labels)}\n",
        "id2label = {i: label for i, label in enumerate(labels)}\n",
        "\n",
        "# Create a DataFrame to load data easily\n",
        "def create_df(data_dir):\n",
        "    df_data = []\n",
        "    for label in os.listdir(data_dir):\n",
        "        label_path = os.path.join(data_dir, label)\n",
        "        if os.path.isdir(label_path):\n",
        "            for image_file in os.listdir(label_path):\n",
        "                image_path = os.path.join(label_path, image_file)\n",
        "                df_data.append({'image': image_path, 'label': label})\n",
        "    return pd.DataFrame(df_data)\n",
        "\n",
        "train_df = create_df(TRAIN_DIR)\n",
        "val_df = create_df(VAL_DIR)\n",
        "\n",
        "# Convert DataFrames to Hugging Face Dataset objects\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "def preprocess_images(examples):\n",
        "    # The Hugging Face processor handles resizing, normalization, etc.\n",
        "    images = [Image.open(path).convert('RGB') for path in examples['image']]\n",
        "    examples['pixel_values'] = image_processor(images=images, return_tensors='pt')['pixel_values']\n",
        "    # Use the globally defined label2id\n",
        "    examples['label'] = [label2id[label] for label in examples['label']]\n",
        "    return examples\n",
        "\n",
        "# Load the ViT image processor\n",
        "image_processor = ViTImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "# Apply preprocessing\n",
        "train_dataset = train_dataset.map(preprocess_images, batched=True)\n",
        "val_dataset = val_dataset.map(preprocess_images, batched=True)\n",
        "\n",
        "# Format the datasets for PyTorch\n",
        "train_dataset.set_format(\"torch\", columns=['pixel_values', 'label'])\n",
        "val_dataset.set_format(\"torch\", columns=['pixel_values', 'label'])\n",
        "\n",
        "# --- 3. MODEL AND TRAINING SETUP ---\n",
        "print(\"Initializing model and training arguments...\")\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    MODEL_CHECKPOINT,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# Load evaluation metric\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./vit-finetuned-fish\",\n",
        "    # CORRECTED: Changed 'evaluation_strategy' to 'eval_strategy'\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\" # Disable logging to external services\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# --- 4. TRAINING ---\n",
        "print(\"\\\\n--- Starting model training with Hugging Face Trainer ---\")\n",
        "train_results = trainer.train()\n",
        "\n",
        "# Save the best model and processor\n",
        "trainer.save_model(\"best_hf_model\")\n",
        "image_processor.save_pretrained(\"best_hf_model\")\n",
        "\n",
        "# --- 5. EVALUATION AND PLOTTING ---\n",
        "print(\"\\\\n--- Evaluating the final model ---\")\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Final evaluation results: {eval_results}\")\n",
        "\n",
        "# Plotting (since Trainer does not provide a history object like Keras)\n",
        "# We can extract logs to visualize\n",
        "logs = trainer.state.log_history\n",
        "train_acc = [l['accuracy'] for l in logs if 'accuracy' in l and 'loss' not in l]\n",
        "val_acc = [l['eval_accuracy'] for l in logs if 'eval_accuracy' in l]\n",
        "train_loss = [l['loss'] for l in logs if 'loss' in l]\n",
        "val_loss = [l['eval_loss'] for l in logs if 'eval_loss' in l]\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.savefig('accuracy_plot.png')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.savefig('loss_plot.png')\n",
        "\n",
        "print(\"Training completed. Plots saved as 'accuracy_plot.png' and 'loss_plot.png'\")\n",
        "print(\"Best model and image processor saved in 'best_hf_model' directory.\")\n",
        "\"\"\")\n",
        "print(\"`train.py` script created.\")\n",
        "\n",
        "# --- Step 4: Run the training script ---\n",
        "print(\"\\nStep 4: Starting model training...\")\n",
        "!python train.py\n",
        "\n",
        "# --- Step 5: Write the app.py script ---\n",
        "print(\"\\nStep 5: Creating `app.py` script...\")\n",
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "\n",
        "try:\n",
        "    model_dir = 'best_hf_model'\n",
        "    model = ViTForImageClassification.from_pretrained(model_dir)\n",
        "    image_processor = ViTImageProcessor.from_pretrained(model_dir)\n",
        "\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading model: {e}\")\n",
        "    st.info(\"Please run `train.py` first to create the model directory.\")\n",
        "    st.stop()\n",
        "\n",
        "# Get class names from the model's configuration\n",
        "class_names = [model.config.id2label[i] for i in range(model.config.num_labels)]\n",
        "\n",
        "st.set_page_config(page_title=\"Fish Species Classifier\", layout=\"centered\")\n",
        "st.title(\"üêü Multiclass Fish Image Classification\")\n",
        "st.markdown(\"Upload an image of a fish and the model will predict its species.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose a fish image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "\n",
        "    if st.button(\"Predict\"):\n",
        "        with st.spinner(\"Classifying...\"):\n",
        "            # Preprocess the image using the ViTImageProcessor\n",
        "            inputs = image_processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "            # Make the prediction\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "            logits = outputs.logits\n",
        "            predicted_class_index = logits.argmax(-1).item()\n",
        "            predicted_class_name = model.config.id2label[predicted_class_index]\n",
        "\n",
        "            # Calculate the confidence score\n",
        "            probabilities = torch.nn.functional.softmax(logits, dim=-1)[0]\n",
        "            confidence_score = probabilities[predicted_class_index].item()\n",
        "\n",
        "            st.success(f\"Prediction: **{predicted_class_name}**\")\n",
        "            st.info(f\"Confidence: {confidence_score*100:.2f}%\")\n",
        "\n",
        "            st.subheader(\"All Class Probabilities\")\n",
        "            for i, name in enumerate(class_names):\n",
        "                st.write(f\"- **{name}**: {probabilities[i].item()*100:.2f}%\")\n",
        "\"\"\")\n",
        "print(\"`app.py` script created.\")\n",
        "\n",
        "# --- Step 6: Run Streamlit and expose it to a public URL with ngrok ---\n",
        "print(\"\\nStep 6: Starting Streamlit app...\")\n",
        "\n",
        "try:\n",
        "    # Kill any existing ngrok tunnels to free up the session\n",
        "    ngrok.kill()\n",
        "    print(\"Killed any existing ngrok tunnels.\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "\n",
        "# Ensure you have a valid ngrok authtoken configured\n",
        "# Note: You can also use `!ngrok config add-authtoken <YOUR_AUTH_TOKEN>`\n",
        "# if it's not already configured in your environment.\n",
        "!ngrok config add-authtoken 3192922EzP7gHi8re9CwKPGKOiv_6FfdFhfDY3SRc4ndhqBbp\n",
        "\n",
        "try:\n",
        "    ngrok_tunnel = ngrok.connect(addr=8501, bind_tls=True)\n",
        "    print(f\"Your Streamlit app is running at: {ngrok_tunnel.public_url}\")\n",
        "\n",
        "    subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok tunnel: {e}\")\n",
        "    print(\"Please check that your authtoken is correct and try again.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85DNpvhs6R4E"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}